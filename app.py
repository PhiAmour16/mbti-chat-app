import streamlit as st
import requests

st.set_page_config(page_title="MBTI å°è©±é æ¸¬")
st.title("MBTI å°è©±é æ¸¬")

# ğŸŒŸ æ¸…é™¤å°è©±æŒ‰éˆ•
if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±ç´€éŒ„"):
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ MBTI åŠ©æ‰‹ã€‚è«‹è¼¸å…¥è¨Šæ¯ï¼Œæˆ‘æœƒæ ¹æ“šå°è©±å…§å®¹é æ¸¬æ‚¨çš„ MBTI é¡å‹ã€‚"}
    ]
    st.session_state.mbti_guess = "å°šæœªé æ¸¬"
    st.rerun()

# åˆå§‹åŒ–å°è©±ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ MBTI åŠ©æ‰‹ã€‚è«‹è¼¸å…¥è¨Šæ¯ï¼Œæˆ‘æœƒæ ¹æ“šå°è©±å…§å®¹é æ¸¬æ‚¨çš„ MBTI é¡å‹ã€‚"}
    ]
if "mbti_guess" not in st.session_state:
    st.session_state.mbti_guess = "å°šæœªé æ¸¬"

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# è¼¸å…¥æ¬„
user_input = st.chat_input("è«‹è¼¸å…¥èŠå¤©å…§å®¹...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # âœ… Spinner æç¤ºï¼šAI æ­£åœ¨å›æ‡‰ä¸­
    with st.spinner("AI æ­£åœ¨å›æ‡‰ä¸­..."):
        headers = {
            "Authorization": f"Bearer {st.secrets['OPENAI_API_KEY']}",
            "Content-Type": "application/json"
        }

        chat_payload = {
            "model": "gpt-4o",
            "messages": st.session_state.messages,
            "temperature": 0.7,
            "max_tokens": 1000
        }

        chat_response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=chat_payload
        )

        if chat_response.status_code == 200:
            reply = chat_response.json()["choices"][0]["message"]["content"]
            st.session_state.messages.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                st.markdown(reply)
        else:
            error = f"API è«‹æ±‚å¤±æ•—ï¼š{chat_response.status_code}"
            st.session_state.messages.append({"role": "assistant", "content": error})
            with st.chat_message("assistant"):
                st.markdown(error)

        # âœ… é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥å¥æ•¸
        user_msgs = [m for m in st.session_state.messages if m["role"] == "user"]
        st.markdown(f"ğŸ—£ï¸ å·²è¼¸å…¥å¥æ•¸ï¼š{len(user_msgs)}")
        if len(user_msgs) < 5:
            st.info("ğŸ“Œ å»ºè­°èˆ‡ AI å¤šèŠå¹¾å¥ï¼ˆè‡³å°‘ 5 å¥ï¼‰ä»¥æé«˜ MBTI é æ¸¬æº–ç¢ºåº¦ã€‚")

        # âœ… MBTI é æ¸¬ï¼ˆä»ç„¶ç…§åŸé‚è¼¯ï¼Œæ¯è¼ªéƒ½è·‘ï¼‰
        analysis_prompt = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¿ƒç†å­¸å°ˆå®¶ï¼Œæ“…é•·æ ¹æ“šå°è©±å…§å®¹æ¨æ¸¬èªªè©±è€…çš„ MBTI é¡å‹ã€‚è«‹åªè¼¸å‡ºå››å­— MBTI é¡å‹ï¼ˆå¦‚ INFPã€ESTJï¼‰ï¼Œä¸éœ€å¤šé¤˜èªªæ˜ã€‚"},
            {"role": "user", "content": "ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…èˆ‡ AI çš„å®Œæ•´å°è©±ï¼Œè«‹é æ¸¬ä½¿ç”¨è€…çš„ MBTI é¡å‹ï¼š\n" + "\n".join([m["content"] for m in user_msgs])}
        ]

        mbti_payload = {
            "model": "gpt-4o",
            "messages": analysis_prompt,
            "temperature": 0.3,
            "max_tokens": 10
        }

        mbti_response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=mbti_payload
        )

        if mbti_response.status_code == 200:
            st.session_state.mbti_guess = mbti_response.json()["choices"][0]["message"]["content"].strip()

# é¡¯ç¤º MBTI æ¨æ¸¬çµæœ
st.divider()
st.subheader("ğŸ” ç›®å‰æ¨æ¸¬çš„ MBTI é¡å‹")
st.markdown(f"**{st.session_state.mbti_guess}**")
